#!/usr/bin/env python

import argparse
import os
from copy import deepcopy
import pymongo
import numpy as np
from utilix import uconfig, xent_collection
from utilix.io import load_runlist
from utilix.config import setup_logger
import straxen
import cutax

from outsource.outsource import Outsource
from outsource.config import DETECTOR_DATA_TYPES


coll = xent_collection()
logger = setup_logger("outsource")


def get_run_ids(
    st,
    detector,
    runlist=None,
    number_from=None,
    number_to=None,
    ignore_processed=False,
):
    """Find data to outsource. Check if dependencies are available in RunDB.
    :param st: straxen context
    :param detector: detector to process
    :param number_from: start run number
    :param number_to: end run number
    :param runlist: list of run numbers to process
    :return: list of run numbers
    """
    include_modes = uconfig.getlist("Outsource", "include_modes", fallback=[])
    exclude_modes = uconfig.getlist("Outsource", "exclude_modes", fallback=[])
    include_sources = uconfig.getlist("Outsource", "include_sources", fallback=[])
    exclude_sources = uconfig.getlist("Outsource", "exclude_sources", fallback=[])
    include_tags = uconfig.getlist("Outsource", "include_tags", fallback=[])
    exclude_tags = uconfig.getlist("Outsource", "exclude_tags", fallback=["bad", "abandon"])

    min_run_number = uconfig.getint("Outsource", "min_run_number", fallback=1)
    max_run_number = uconfig.getint("Outsource", "min_run_number", fallback=999999)
    if number_from is not None:
        min_run_number = max(number_from, min_run_number)
    if number_to is not None:
        max_run_number = min(number_to, max_run_number)

    number_query = {"$gte": min_run_number, "$lte": max_run_number}
    if runlist:
        number_query["$in"] = runlist

    include_data_types = uconfig.getlist("Outsource", "include_data_types")

    # Setup queries for different detectors
    basic_queries = []
    basic_queries_has_raw = []
    basic_queries_to_process = []

    for det, det_info in DETECTOR_DATA_TYPES.items():
        if detector != "all" and detector != det:
            logger.warning(f"Skipping {det} data")
            continue

        # Check if the data_type is in the list of data_types to outsource
        data_type_to_process = [d for d in det_info["to_process"] if d in include_data_types]

        if not data_type_to_process:
            logger.warning(f"Skipping {det} data")
            continue

        # Basic query
        basic_query = {"number": number_query, "detectors": det}
        for key, values in zip(
            ["source", "mode", "tags.name"],
            [
                [include_sources, exclude_sources],
                [include_modes, exclude_modes],
                [include_tags, exclude_tags],
            ],
        ):
            _query = dict()
            if values[0]:
                _query["$in"] = values[0]
            if values[1]:
                _query["$nin"] = values[1]
            if _query:
                basic_query[key] = deepcopy(_query)

        basic_queries.append(basic_query)

        has_raw_data_type_query = {
            "$elemMatch": {
                "type": det_info["raw"],
                "host": "rucio-catalogue",
                "status": "transferred",
                "location": {"$in": uconfig.getlist("Outsource", "raw_records_rse")},
            }
        }
        to_process_data_type_query = [
            {
                "data": {
                    "$not": {
                        "$elemMatch": {
                            "host": "rucio-catalogue",
                            "type": data_type,
                            "status": "transferred",
                            "did": {"$regex": st.key_for("0", data_type).lineage_hash},
                        }
                    }
                }
            }
            for data_type in data_type_to_process
        ]

        # Basic query with raw data
        basic_query_has_raw = deepcopy(basic_query)
        basic_query_has_raw["data"] = has_raw_data_type_query
        basic_queries_has_raw.append(basic_query_has_raw)

        # Basic query without to_process data
        basic_query_to_process = deepcopy(basic_query)
        basic_query_to_process["$or"] = to_process_data_type_query
        basic_queries_to_process.append(basic_query_to_process)

    full_query_basic = {"$or": basic_queries}
    full_query_basic_has_raw = {"$or": basic_queries_has_raw}
    full_query_basic_to_process = {"$or": basic_queries_to_process}

    cursor_basic = coll.find(
        full_query_basic,
        {"number": 1, "_id": 0, "mode": 1},
        limit=uconfig.getint("Outsource", "max_daily", fallback=None),
        sort=[("number", -1)],
    )
    cursor_basic_has_raw = coll.find(
        full_query_basic_has_raw,
        {"number": 1, "_id": 0, "mode": 1},
        limit=uconfig.getint("Outsource", "max_daily", fallback=None),
        sort=[("number", -1)],
    )
    cursor_basic_to_process = coll.find(
        full_query_basic_to_process,
        {"number": 1, "_id": 0, "mode": 1},
        limit=uconfig.getint("Outsource", "max_daily", fallback=None),
        sort=[("number", -1)],
    )

    runlist_basic = [r["number"] for r in cursor_basic]
    if not runlist_basic:
        raise ValueError("Nothing was found in RunDB for even the most basic requirement.")

    runlist_basic_has_raw = [r["number"] for r in cursor_basic_has_raw]
    logger.warning(
        "The following are the run numbers passing the basic queries and "
        f"have raw data available: {runlist_basic_has_raw}"
    )
    runlist_basic_to_process = [r["number"] for r in cursor_basic_to_process]
    logger.warning(
        "The following are the run numbers passing the basic queries and "
        f"have to be processed: {runlist_basic_to_process}"
    )

    if ignore_processed:
        runlist = list(set(runlist_basic_has_raw))
    else:
        runlist = list(set(runlist_basic_to_process) & set(runlist_basic_has_raw))

    return runlist


def main():
    parser = argparse.ArgumentParser("Outsource")
    parser.add_argument("--context", required=True, help="Name of context, imported from cutax.")
    parser.add_argument(
        "--xedocs_version", required=True, help="global version, an argument for context."
    )
    parser.add_argument(
        "--image",
        default="development",
        help=(
            "Singularity image. Accepts either a full path or a single name "
            "and assumes a format like this: "
            "/cvmfs/singularity.opensciencegrid.org/xenonnt/base-environment:{image}"
        ),
    )
    parser.add_argument(
        "--detector",
        default="all",
        help=(
            "Detector to focus on. If 'all' (default) will consider all three detectors. "
            "Otherwise pass a single one of 'tpc', 'neutron_veto', 'muon_veto'. "
            "Pairs of detectors not yet supported. "
        ),
        choices=["all", "tpc", "muon_veto", "neutron_veto"],
    )
    parser.add_argument(
        "--workflow_id",
        help="Custom workflow_id of workflow. If not passed, inferred from today's date.",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help=(
            "Force overwrites workflows and reprocesses data even if processed already. "
            "Will not re-upload to rucio though."
        ),
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help=(
            "Debug mode. Does not automatically submit the workflow, "
            "and jobs do not update RunDB nor upload to rucio."
        ),
    )
    parser.add_argument("--from", dest="number_from", type=int, help="Run number to start with")
    parser.add_argument("--to", dest="number_to", type=int, help="Run number to end with")
    parser.add_argument("--mode", nargs="*", help="Space separated run mode(s) to consider")
    parser.add_argument(
        "--run", nargs="*", type=int, help="Space separated specific run number(s) to process"
    )
    parser.add_argument("--runlist", type=str, help="Path to a runlist file")
    parser.add_argument(
        "--ignore_processed",
        dest="ignore_processed",
        action="store_true",
        help="Ignore runs that have already been processed",
    )
    parser.add_argument(
        "--rucio_upload",
        dest="rucio_upload",
        action="store_true",
        help="Upload data to rucio after processing",
    )
    parser.add_argument(
        "--rundb_update",
        dest="rundb_update",
        action="store_true",
        help="Update RunDB after processing",
    )
    args = parser.parse_args()

    if args.ignore_processed and args.rucio_upload:
        raise RuntimeError("Cannot upload to rucio in debug mode.")

    if not args.rucio_upload and args.rundb_update:
        raise RuntimeError("Cannot update RunDB without uploading to rucio.")

    st = getattr(cutax.contexts, args.context)(xedocs_version=args.xedocs_version)

    if args.run and args.runlist:
        raise RuntimeError("Cannot pass both --run and --runlist. Please choose one.")

    if args.run:
        _runlist = args.run
    elif args.runlist:
        _runlist = load_runlist(args.runlist)
    else:
        _runlist = None

    runlist = get_run_ids(
        st,
        detector=args.detector,
        runlist=_runlist,
        number_from=args.number_from,
        number_to=args.number_to,
        ignore_processed=args.ignore_processed,
    )
    if set(_runlist) - set(runlist):
        logger.warning(
            "The following run numbers were not processible "
            f"after checking dependeicies in the RunDB: {set(_runlist) - set(runlist)}"
        )
    if not runlist:
        raise RuntimeError(
            "Cannot find any runs matching the criteria specified in your input and xenon_config!"
        )

    # This object contains all the information needed to submit the workflow
    outsource = Outsource(
        runlist,
        context_name=args.context,
        xedocs_version=args.xedocs_version,
        image=args.image,
        workflow_id=args.workflow_id,
        rucio_upload=args.rucio_upload,
        rundb_update=args.rundb_update,
        force=args.force,
        debug=args.debug,
    )

    # Finally submit the workflow
    outsource.submit()


if __name__ == "__main__":
    main()
