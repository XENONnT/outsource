#!/usr/bin/env python

import argparse
import os
from utilix.io import load_runlist
from utilix import xent_collection
from utilix.rundb import cmt_local_valid_range
import cutax
import straxen
import numpy as np

from outsource.Outsource import Outsource, DEFAULT_IMAGE
from outsource.Config import config


# do a query to see if these data types are present
DETECTOR_DTYPES = {'tpc': {'raw': 'raw_records',
                           'to_process': ['peaklets', 'event_info', 'peak_basics', 'peak_basics_he', 
                                          'event_pattern_fit', 'event_area_per_channel', 'event_top_bottom_params',
                                          'event_ms_naive', 'event_shadow', 'event_ambience', 
                                          'peak_s1_positions_cnn', 'afterpulses']
                          },
                   'neutron_veto': {'raw': 'raw_records_nv',
                                    'to_process': ['hitlets_nv', 'events_nv']
                                    },
                   'muon_veto': {'raw': 'raw_records_mv',
                                 'to_process': ['events_mv']
                                 }
                   }

coll = xent_collection()


def data_find(st, detector, number_from=None, number_to=None,
              specify_modes=None, specify_sources=None,
              runlist=None
              ):
    """Find data to outsource. Check if dependencies are available in RunDB.
    :param st: straxen context
    :param detector: detector to process
    :param number_from: start run number
    :param number_to: end run number
    :param specify_modes: list of run modes to process
    :param specify_sources: list of sources to process
    :param runlist: list of run numbers to process
    :return: list of run numbers
    """
    exclude_tags = ['bad', 'abandon']
    exclude_modes = config.get_list('Outsource', 'exclude_modes')
    min_run_number = config.getint('Outsource', 'min_run_number')
    max_run_number = 999999
    if number_from is not None:
        min_run_number = max(number_from, min_run_number)
    if number_to is not None:
        max_run_number = min(number_to, max_run_number)

    hashes = {key: val['hash'] for key, val in st.provided_dtypes().items()}

    # setup queries for different detectors
    basic_queries = []
    basic_queries_w_raw = []
    basic_queries_wo_to_process = []

    for det, det_info in DETECTOR_DTYPES.items():
        if detector != 'all' and detector != det:
            print(f"Skipping {det} data")
            continue

        # check if gain model is valid
        if det == 'tpc':
            gain_model = 'pmt_000_gain_xenonnt'
            straxen_opt = 'gain_model'
        elif det == 'neutron_veto':
            gain_model = 'n_veto_000_gain_xenonnt'
            straxen_opt = 'gain_model_nv'
        elif det == 'muon_veto':
            gain_model = 'mu_veto_000_gain_xenonnt'
            straxen_opt = 'gain_model_mv'
        else:
            raise NotImplementedError

        # FIXME this feature actually should be retired
        local_gain_version = st.config.get(straxen_opt)
        gain_range = cmt_local_valid_range(gain_model, local_gain_version)

        # We will check if the data type in the following list is already present in the runDB
        dtype_to_check_avail_list = det_info['to_process'] 

        # Check if the data type is in the list of data types to outsource
        outsource_dtypes_str = config.get('Outsource', 'dtypes')
        dtype_to_check_avail_list = [d for d in dtype_to_check_avail_list if d in outsource_dtypes_str]

        if not len(dtype_to_check_avail_list):
            print(f"Skipping {det} data because no data types to outsource were found in intersection of outsource dtypes and %s to processdtypes"%(det))
            continue

        raw_dtype = det_info['raw']

        # Check if the data type (peaklets, event_info, etc) is already present in the runDB, added by ruciocatalogue
        to_process_dtype_query = [{'data': {'$not': {'$elemMatch': {'host': 'rucio-catalogue',
                                                        'type': dtype,
                                                        'status': 'transferred',
                                                        'did': {'$regex': hashes[dtype]},
                                                       }
                                        }
                                }
                        }
                        for dtype in dtype_to_check_avail_list
                      ]
        
        # FIXME: we want the raw data location to be flexible, as specified in xenon_config for raw_records_rse
        has_raw_dtype_query = {'$elemMatch': {'type': raw_dtype,
                                         'host': 'rucio-catalogue',
                                         'status': 'transferred',
                                         'location': {'$in': config.get('Outsource', 'raw_records_rse').split(',')}
                                }}

        if specify_modes:
            mode_query = {'$in': specify_modes}
        else:
            mode_query = {'$not': {'$in': exclude_modes}}

        number_query = {'$gte': min_run_number, '$lte': max_run_number}

        if runlist:
            number_query['$in'] = runlist

        # Basic query
        basic_query = {'number': number_query,
                       'tags.name': {'$not': {'$in': exclude_tags}},
                       'start': {'$gt': gain_range[0],
                                 '$lt': gain_range[1]},
                       'mode': mode_query.copy(),
                       'detectors': det,
                      }
        if specify_sources:
            basic_query['source'] = {'$in': specify_sources}
        basic_queries.append(basic_query)

        # Basic query with raw data
        basic_query_w_raw = basic_query.copy()
        basic_query_w_raw['data'] = has_raw_dtype_query
        basic_queries_w_raw.append(basic_query_w_raw)


        # Basic query without to_process data
        basic_query_wo_to_process = basic_query.copy()
        basic_query_wo_to_process['$or'] = to_process_dtype_query
        basic_queries_wo_to_process.append(basic_query_wo_to_process)


    full_query_basic = {'$or': basic_queries}
    full_query_basic_w_raw = {'$or': basic_queries_w_raw}
    full_query_basic_wo_to_process = {'$or': basic_queries_wo_to_process}

    cursor_basic = coll.find(full_query_basic, {'number': 1, '_id': 0, 'mode': 1},
                       limit=config.getint('Outsource', 'max_daily', fallback=None),
                       sort=[('number', -1)]
                       )
    cursor_basic_w_raw = coll.find(full_query_basic_w_raw, {'number': 1, '_id': 0, 'mode': 1},
                        limit=config.getint('Outsource', 'max_daily', fallback=None),
                        sort=[('number', -1)]
                        )
    cursor_basic_wo_to_process = coll.find(full_query_basic_wo_to_process, {'number': 1, '_id': 0, 'mode': 1},
                        limit=config.getint('Outsource', 'max_daily', fallback=None),
                        sort=[('number', -1)]
                        )

    modes_basic = []
    runlist_basic = []
    modes_basic_w_raw = []
    runlist_basic_w_raw = []
    modes_basic_wo_to_process = []
    runlist_basic_wo_to_process = []

    if len(cursor_basic):
        for r in cursor_basic:
            if r['mode'] not in modes_basic:
                modes_basic.append(r['mode'])
            runlist_basic.append(r['number'])
    print(f"Run modes for runs passing the basic queires: {', '.join(modes_basic)}")
    print("The following are the run numbers passing the basic queries:")
    print(runlist_basic)
    print("------------------------------------------")

    for r in cursor_basic_w_raw:
        if r['mode'] not in modes_basic_w_raw:
            modes_basic_w_raw.append(r['mode'])
        runlist_basic_w_raw.append(r['number'])
    print(f"Run modes for runs passing the basic queires and have raw data available: {', '.join(modes_basic_w_raw)}")
    print("The following are the run numbers passing the basic queries and have raw data available:")
    print(runlist_basic_w_raw)
    print("------------------------------------------")

    for r in cursor_basic_wo_to_process:
        if r['mode'] not in modes_basic_wo_to_process:
            modes_basic_wo_to_process.append(r['mode'])
        runlist_basic_wo_to_process.append(r['number'])
    print("The following are the run numbers passing the basic queries and have no to_process data available:")
    print(runlist_basic_wo_to_process)
    print("------------------------------------------")

    runlist = list(set(runlist_basic_wo_to_process) & set(runlist_basic_w_raw))

    return runlist


def main():
    parser = argparse.ArgumentParser("Outsource")
    parser.add_argument('--context', required=True, help="[REQUIRED] Name of context, imported from cutax.")
    parser.add_argument('--debug', action='store_true',
                        help='Debug mode. Does not automatically submit the workflow, '
                             'and jobs do not update runsDB nor upload to rucio.')
    parser.add_argument('--name', help="Custom name of workflow directory. If not passed, inferred from today's date")
    parser.add_argument('--image', default=DEFAULT_IMAGE,
                        help='Singularity image. Accepts either a full path or a single name '
                             'and assumes a format like this: '
                             '/cvmfs/singularity.opensciencegrid.org/xenonnt/base-environment:{image}')
    parser.add_argument('--force', action='store_true',
                        help='Force overwrites workflows and reprocesses data even if processed already. '
                             'Will not re-upload to rucio though.')
    parser.add_argument('--dry-run', dest='dry_run', action='store_true',
                        help='Dry run. Does not submit the workflow, but prints the command that would be run.')
    parser.add_argument('--detector', default='all',
                        help="Detector to focus on. If 'all' (default) will consider all three detectors. "
                             "Otherwise pass a single one of 'tpc', 'neutron_veto', 'muon_veto'."
                             " Pairs of detectors not yet supported. ",
                        choices=['all', 'tpc', 'muon_veto', 'neutron_veto'])
    parser.add_argument('--from', type=int, help='Run number to start with', dest='number_from')
    parser.add_argument('--to', type=int, help='Run number to end with', dest='number_to')
    parser.add_argument('--mode', nargs='*', help='Space separated run mode(s) to consider. ')
    parser.add_argument('--run', nargs='*', type=int, help='space separated specific run number(s) to process')
    parser.add_argument('--runlist', type=str, help='Path to a runlist file')
    parser.add_argument('--source', type=str, nargs='*', help='Space separated source(s) to consider')
    args = parser.parse_args()

    upload_to_rucio = update_db = True

    if args.debug:
        upload_to_rucio = update_db = False

    # register event_info manually, otherwise in cutax v1.15.0 you will have
    # cutax.plugins.acsideband.ACSideband for event_info
    st = getattr(cutax.contexts, args.context)()
    del st._plugin_class_registry['event_info']
    st.register(straxen.EventInfo)
    # remove cuts if there is any
    all_plugin_keys_registrerd = list(st._plugin_class_registry.keys())
    for registered_plugin in all_plugin_keys_registrerd:
        if ('cut' in registered_plugin) or ('cuts' in registered_plugin):
            del st._plugin_class_registry[registered_plugin]
        elif 'cut' in str(st._plugin_class_registry[registered_plugin]):
            del st._plugin_class_registry[registered_plugin]
    # remove diffusion_constant if there is one to avoid warning message
    if "diffusion_constant" in st.config.keys():
        del st.config["diffusion_constant"]

    if args.run and args.runlist:
        raise RuntimeError("Cannot pass both --run and --runlist. Please choose one.")

    # subset of runs to consider during data find
    _runlist = None

    if args.run:
        _runlist = args.run

    elif args.runlist:
        _runlist = load_runlist(args.runlist)
    runlist = data_find(st,
                        args.detector,
                        number_from=args.number_from,
                        number_to=args.number_to,
                        specify_modes=args.mode,
                        runlist=_runlist,
                        specify_sources=args.source
                        )
    if len(runlist)!=len(_runlist):
        print("The following run numbers were not processible after checking dependeicies in the runsDB:")
        print(set(_runlist)-set(runlist))
    assert len(runlist), "Cannot find any runs matching the criteria specified in your input and xenon_config!"
    if args.dry_run:
        print(runlist)
        print(f"DRY RUN: would process {len(runlist)} runs "
              f"from {min(runlist)} to {max(runlist)}.")
        return

    image = args.image
    # Assume that if the image is not a full path, it is a name
    if not os.path.exists(image):
        image = f"/cvmfs/singularity.opensciencegrid.org/xenonnt/base-environment:{image}"

    # This object contains all the information needed to submit the workflow
    outsource = Outsource(runlist,
                          args.context,
                          debug=args.debug,
                          image=image,
                          wf_id=args.name,
                          upload_to_rucio=upload_to_rucio,
                          update_db=update_db,
                          force_rerun=args.force
                          )

    # Finally submit the workflow
    outsource.submit_workflow()


if __name__ == '__main__':
    main()
